{"cells":[{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"## Importing packages\n\n# This R environment comes with all of CRAN and many other helpful packages preinstalled.\n# You can see which packages are installed by checking out the kaggle/rstats docker image: \n# https://github.com/kaggle/docker-rstats\n\nlibrary(tidyverse) # metapackage with lots of helpful functions\n\n## Running code\n\n# In a notebook, you can run a single code cell by clicking in the cell and then hitting \n# the blue arrow to the left, or by clicking in the cell and pressing Shift+Enter. In a script, \n# you can run code by highlighting the code you want to run and then clicking the blue arrow\n# at the bottom of this window.\n\n## Reading in files\n\n# You can access files from datasets you've added to this kernel in the \"../input/\" directory.\n# You can see the files added to this kernel by running the code below. \n\nlist.files(path = \"../input\")\n\n## Saving data\n\n# If you save any files or images, these will be put in the \"output\" directory. You \n# can see the output directory by committing and running your kernel (using the \n# Commit & Run button) and then checking out the compiled version of your kernel.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"library(caret)\nlibrary(ggplot2)\nlibrary(dplyr)\ndata<-read_csv(\"../input/Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim(data)\nglimpse(data)\nsummary(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NA value treatment\nsapply(data, function(df){sum(is.na(df))})\ndata<-na.omit(data)\nsum(is.na(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Discarding insignificant variable\ndata<-data[,-1]\ndim(data)\n#Fitting logistic regression\nglm.fit<-glm(Churn~.,new,family=\"binomial\")\npred<-predict(glm.fit,new,type=\"response\")\npred<-ifelse(pred>0.5,1,0)\ntable(new$Churn,pred)\nmisClassError<-mean(pred!=new$Churn)\nprint(paste('Accuracy=', 1-misClassError))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A different approach\n#by creating dummy variables\ndmy<-dummyVars(Churn~.,data,fullRank=TRUE)\nnew<-data.frame(predict(dmy,data))\ndim(new)\nnew$Churn<-data$Churn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set.seed(1000)\nindex<-createDataPartition(new$Churn,p=0.8,list=FALSE)\ntrain<-new[index,]\ntest<-new[-index,]\nmodel<-train(Churn~.,train,method=\"glm\",family=\"binomial\")\npred<-predict(model, test, type=\"prob\")\nsummary(model)\nconfusionMatrix(pred,test[[\"Churn\"]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k-fold cross-validation\ncontrol<-trainControl(method = \"repeatedcv\", number = 10, repeats=3, summaryFunction=twoClassSummary, classProbs=TRUE,verboseIter=FALSE )\nmodel<-train(Churn~.,train,method=\"glm\",family=\"binomial\",trControl=control)\npred<-predict(model, test, type=\"prob\")\nsummary(model)\nconfusionMatrix(pred,test[[\"Churn\"]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#variable importance\nvarImp(model)\n#ROC-AUC curve\nlibrary(ROCR)\nROCRPred<-prediction(pred,test$Churn)\nROCRPref<-performance(ROCRpred,measure='tpr',x.measure='fpr')\nplot(ROCRpref)\nauc<-performance(ROCRPred,measure=\"auc\")\n#Finally we would be able to build a model with siginificant features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generalized Linear Model\nglmnet_mod<-train(Churn~.,train,metric=\"ROC\",method=\"glmnet\",trControl=control,preProcess=c(\"center\",\"scale\"))\nplot(glmnet_mod)\nglmnet_mod$bestTune$alpha\nglmnet_pred<-predict(glmnet_mod,test)\ncm<-confusionMatrix(glmnet_pred,test[[\"churn\"]])\naccuracy<-cm$overall[c(1,3,4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Implication of RanomForest\nrf_mod<-train(Churn~.,train,metric=\"ROC\",method=\"ranger\",trControl=control)\nplot(rf_mod)\nrf_mod$bestTune$alpha\nrf_pred<-predict(rf_mod,test)\ncm<-confusionMatrix(rf_pred,test[[\"churn\"]])\naccuracy<-cm$overall[c(1,3,4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K-nearest neighbour\nknn_mod<-train(Churn~.,train,method=\"knn\",trControl=control, preProcess=c(\"center\",\"scale\"), tuneLength=50)\nknn_pred<-predict(knn_mod,test)\ncm<-confusionMatrix(knn_pred,test[[\"Churn\"]])\naccuracy<-cm$overall[c(1,3,4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support Vector Classifier\ngrid<-expand.grid(C=c(0.01,0.05,0.1,0.25,0.5))\nsvm_mod<-train(Churn~.,train,method=\"svmLinear\",trControl=control,preProcess=c('center','scale'),tuneLength=6,tuneGrid=grid)\nprint(svm_mod)\nplot(svm_mod)\nsvm_pred<-predict(svm_mod,test)\ncm<-confusionMatrix(svm_pred,test[[\"Churn\"]])\naccuracy<-cm$overall[c(1,3,4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model comparison\nm_list<-list(\"Logistic\"=model,\"Glmnet\"=glmnet_mod,\"RandomForest\"=rf_mod,\"Knn\"=knn_mod,\"SVM\"=svm_mod)\nresamples<-resamples(m_list)\ndotplot(resamples,metric=\"ROC\")\n#models<-c(\"Logistic\",\"Glmnet\",\"RandomForest\",\"Knn\",\"SVM\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":4}